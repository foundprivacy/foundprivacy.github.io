{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VsOF8JbFaNR"
      },
      "source": [
        "# Foundations of Privacy HW3 Programming Component\n",
        "In this assignment, you will play with the DPSGD implementation in tensorflow privacy. \n",
        "\n",
        "The coding exercise is at the end of the document. You should run all your code and download the ipynb file. For the submission, you should create a zip file that contains both the written component (pdf) and the programming component (ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPrQCpRSEKR9"
      },
      "source": [
        "# Loading basic libraries\n",
        "We will begin by importing/installing these libraries. \n",
        "* [numpy](https://docs.scipy.org/doc/)\n",
        "* [tensorflow](https://www.tensorflow.org/overview)\n",
        "* [tensorflow privacy](https://github.com/tensorflow/privacy)\n",
        "\n",
        "You are encouraged to read the documentation of these libraries, especially these tensorflow privacy [tutorials](https://github.com/tensorflow/privacy/tree/master/tutorials)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQN5xrUoW8jX"
      },
      "source": [
        "# Other basic functions \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "!pip -q install tensorflow_privacy==0.7.2\n",
        "\n",
        "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
        "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
        "from tensorflow_privacy.privacy.keras_models.dp_keras_model import DPSequential\n",
        "\n",
        "\n",
        "from absl import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4UXDQebFrGT"
      },
      "source": [
        "# Loading Data Set\n",
        "The MNIST data set is perhaps the most commonly used data set for testing ML algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp8iwCXdXJes"
      },
      "source": [
        "def load_mnist():\n",
        "  \"\"\"Loads MNIST and preprocesses to combine training and validation data.\"\"\"\n",
        "  train, test = tf.keras.datasets.mnist.load_data()\n",
        "  train_data, train_labels = train\n",
        "  test_data, test_labels = test\n",
        "\n",
        "  train_data = np.array(train_data, dtype=np.float32) / 255\n",
        "  test_data = np.array(test_data, dtype=np.float32) / 255\n",
        "\n",
        "  train_data = train_data.reshape((train_data.shape[0], 28, 28, 1))\n",
        "  test_data = test_data.reshape((test_data.shape[0], 28, 28, 1))\n",
        "\n",
        "  train_labels = np.array(train_labels, dtype=np.int32)\n",
        "  test_labels = np.array(test_labels, dtype=np.int32)\n",
        "\n",
        "  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
        "  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "  assert train_data.min() == 0.\n",
        "  assert train_data.max() == 1.\n",
        "  assert test_data.min() == 0.\n",
        "  assert test_data.max() == 1.\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "# Load training and test data.\n",
        "train_data, train_labels, test_data, test_labels = load_mnist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_LrLb8BrESL"
      },
      "source": [
        "# A snapshot of the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_data[i].squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vu1mlfiF-oo"
      },
      "source": [
        "# Privacy Accountant\n",
        "The tensorflow library comes with a nice tool (sometimes called the *privacy accountant*) that computes the value of epsilon when it is given the parameters of DPSGD and the specifed value of delta.\n",
        "\n",
        "You can essentially think of this as an optimized tool that applies the *advanced composition theorem* for you automatically.\n",
        "\n",
        "* steps: T\n",
        "* noise_multiplier: sigma / clip_norm. In other words, the standard deviation of the Gaussian noise sigma = clip_norm * noise_multiplier.\n",
        "* batch_size = |B_t|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuK1KJPE_W7L"
      },
      "source": [
        "def compute_epsilon(steps, noise_multiplier, batch_size):\n",
        "  \"\"\"Computes epsilon value for given hyperparameters.\"\"\"\n",
        "  if noise_multiplier == 0.0:\n",
        "    return float('inf')\n",
        "  orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
        "  sampling_probability = batch_size / 60000\n",
        "  rdp = compute_rdp(\n",
        "      q=sampling_probability,\n",
        "      noise_multiplier=noise_multiplier,\n",
        "      steps=steps,\n",
        "      orders=orders)\n",
        "  # Delta is set to 1e-6, which is much less than 60000, the number of training points.\n",
        "  return get_privacy_spent(orders, rdp, target_delta=1e-6)[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiKKTatdILYQ"
      },
      "source": [
        "# Creating a machine learning model\n",
        "The following code creates a neural network architecture for image classification. You do not need to understand this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI_FGpMRL-Gm"
      },
      "source": [
        "# Define a Convolutional Neural Network Architecture (sequential Keras model)\n",
        "layers = [\n",
        "      tf.keras.layers.Conv2D(\n",
        "          16,\n",
        "          8,\n",
        "          strides=2,\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPool2D(2, 1),\n",
        "      tf.keras.layers.Conv2D(\n",
        "          32, 4, strides=2, padding='valid', activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(2, 1),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I6DhSd6Ik2A"
      },
      "source": [
        "# DPSGD Code\n",
        "The following code runs the implementation of DPSGD in tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ1nc3_6Jblv"
      },
      "source": [
        "def run_dpsgd(params):\n",
        "  dpsgd = params[\"dpsgd\"]\n",
        "  learning_rate = params[\"learning_rate\"]\n",
        "  noise_multiplier = params[\"noise_multiplier\"]\n",
        "  l2_norm_clip = params[\"l2_norm_clip\"]\n",
        "  batch_size = params[\"batch_size\"]\n",
        "  epochs = params[\"epochs\"]\n",
        "  microbatches = params[\"microbatches\"]\n",
        "\n",
        "  # Compute the privacy budget that will be expended. You can compute it without running the algorithm\n",
        "  if dpsgd:\n",
        "    eps = compute_epsilon(epochs * 60000 // batch_size, noise_multiplier, batch_size)\n",
        "    print('For delta=1e-6, the current epsilon is: %.2f' % eps)\n",
        "  else:\n",
        "    print('Trained with vanilla non-private SGD optimizer')\n",
        "\n",
        "  logging.set_verbosity(logging.INFO)\n",
        "  if dpsgd and batch_size % microbatches != 0:\n",
        "    raise ValueError('Number of microbatches should divide evenly batch_size')\n",
        "\n",
        "  # Define DPSGD optimizer\n",
        "  if dpsgd:\n",
        "    model = DPSequential(\n",
        "        l2_norm_clip=l2_norm_clip,\n",
        "        noise_multiplier=noise_multiplier,\n",
        "        layers=layers)\n",
        "  else:\n",
        "    model = tf.keras.Sequential(layers=layers)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  # Compile model with Keras\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "  # Train model with Keras\n",
        "  history = model.fit(\n",
        "      train_data,\n",
        "      train_labels,\n",
        "      epochs=epochs,\n",
        "      validation_data=(test_data, test_labels),\n",
        "      batch_size=batch_size)\n",
        "\n",
        "  return history"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbUadOykKJTK"
      },
      "source": [
        "# Trying out different DPSGD parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB0dCLclMHYU"
      },
      "source": [
        "#Defining parameters for running DP-SGD\n",
        "example_params = {\n",
        "  \"dpsgd\" : True, # you should always set this to be True in the HW\n",
        "  \"learning_rate\" : 0.15, # eta\n",
        "  \"noise_multiplier\" : 1,\n",
        "  \"l2_norm_clip\" : 1.0,\n",
        "  \"batch_size\" : 250,\n",
        "  \"epochs\" : 3,\n",
        "  \"microbatches\" : 50\n",
        "}\n",
        "\n",
        "history = run_dpsgd(example_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxKR-C6CCq7z"
      },
      "source": [
        "# You could replay the history \n",
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQO2E2NIXMub"
      },
      "source": [
        "## Problem: searching DP-SGD parameters\n",
        "Now it's your turn. Find three sets of parameters such that the resulting epsilon is less than 1 and delta is 1e-6.\n",
        "\n",
        "Identify which one has the highest validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfgwzaljCrxD"
      },
      "source": [
        "# FILL IN\n",
        "params_1 = {}\n",
        "\n",
        "history = run_dpsgd(params_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNWPX9x9YSDQ"
      },
      "source": [
        "# FILL IN\n",
        "params_2 = {}\n",
        "\n",
        "history = run_dpsgd(params_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdeP2R7YZaN"
      },
      "source": [
        "# FILL IN\n",
        "params_3 = {}\n",
        "\n",
        "history = run_dpsgd(params_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgI8r_D7e0jc"
      },
      "source": [
        "### Question\n",
        "What is the highest validation and training accuracy you get? What would be your strategy to choose the parameters to optimize accuracy subject to a fixed level of privacy.\n",
        "\n",
        "(*Double click to type in your answer*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EZppfGPe7gH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}